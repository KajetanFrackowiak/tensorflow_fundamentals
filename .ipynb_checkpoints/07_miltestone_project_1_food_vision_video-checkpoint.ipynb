{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4a5f286",
   "metadata": {},
   "source": [
    "# Milestone Projet 1: Food Vision Big"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1025040",
   "metadata": {},
   "source": [
    "## Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef00ed6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce GTX 1650 (UUID: GPU-f010ab2c-9f8a-dfc2-d888-045d09377d67)\r\n"
     ]
    }
   ],
   "source": [
    "# Get GPU name\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c1e66a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3571115027.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Note: As of May 2023, there have been some issues with TensorFlow versions 2.9-2.12\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    " Note: As of May 2023, there have been some issues with TensorFlow versions 2.9-2.12\n",
    "# with the following code. \n",
    "# However, these seemed to have been fixed in version 2.13+.\n",
    "# TensorFlow version 2.13 is available in tf-nightly as of May 2023 (will be default in Google Colab soon).\n",
    "# Therefore, to prevent errors we'll install tf-nightly first.\n",
    "# See more here: https://github.com/mrdbourke/tensorflow-deep-learning/discussions/550 \n",
    "\n",
    "# Install tf-nightly (required until 2.13.0+ is the default in Google Colab)\n",
    "!pip install -U -q tf-nightly\n",
    "\n",
    "# Check TensorFlow version (should be minimum 2.4.0+ but 2.13.0+ is better)\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# Add timestamp\n",
    "import datetime\n",
    "print(f\"Notebook last run (end-to-end): {datetime.datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17c4aaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 'helper_functions.py' already exists, skipping download.\n"
     ]
    }
   ],
   "source": [
    "# Get helper functions file\n",
    "import os \n",
    "\n",
    "if not os.path.exists(\"helper_functions.py\"):\n",
    "    !wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
    "else:\n",
    "    print(\"[INFO] 'helper_functions.py' already exists, skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e1384b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import series of helper functions for the notebook (we've created/used these in previous notebooks)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelper_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_tensorboard_callback, plot_loss_curves, compare_historys\n",
      "File \u001b[0;32m~/Documents/tensorflow_fundamentals/helper_functions.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### We create a bunch of helpful functions throughout the course.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m### Storing them here so they're easily accessible.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Create a function to import an image and resize it to be able to be used with our model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_and_prep_image\u001b[39m(filename, img_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m224\u001b[39m, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Import series of helper functions for the notebook (we've created/used these in previous notebooks)\n",
    "from helper_functions import create_tensorboard_callback, plot_loss_curves, compare_historys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5285ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get TensorFlow Datasets\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12729232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all available datasets in TFDS\n",
    "datasets_list = tfds.list_builders()\n",
    "\n",
    "# Set our target dataset and see if it exists\n",
    "target_dataset = \"food101\"\n",
    "print(f\"'{target_dataset}' in TensorFlow Datasets: {target_dataset in datasets_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3803ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data (takes about 5-6 minutes in Google Colab)\n",
    "(train_data, test_data), ds_info = tfds.load(name=\"food101\", # target dataset to get from TFDS\n",
    "                                             split=[\"train\", \"validation\"], # what splits of data should we get? note: not all datasets have train, valid, test\n",
    "                                             shuffle_files=True, # shuffle files on download?\n",
    "                                             as_supervised=True, # download data in tuple format (sample, label), e.g. (image, label)\n",
    "                                             with_info=True) # include dataset metadata? if so, tfds.load() returns tuple (data, ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbd6dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_info.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84359269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139217ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
